<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Jinbin Bai Homepage">
    <meta name="author" content="Jinbin Bai">
    <link rel="shortcut icon" href="images/favicon.ico" />
    <meta name="google-site-verification" content="Befm1EhO7nNT_5JmVbLWxjiqeoQRXSUluMPi84niqI4" />
    <!-- <script>
                var browserLanguage = navigator.language || navigator.userLanguage;
                if (browserLanguage.toLowerCase() === 'zh-cn') {
                    window.location.href = 'https://www.baidu.com'; 
                }
            </script> -->
    <title>Jinbin Bai Homepage</title>

    <style>
        /* 应用Comic Sans MS字体到页面中所有文本 */
        body {
            /* 使用Comic Sans MS字体，如果无法加载则使用默认字体 */
            font-family: "Comic Sans MS", sans-serif;

        }

        /* 也可以为特定元素设置字体 */
        h1,
        h2,
        p {
            font-family: "Comic Sans MS", sans-serif;
        }

        /* 其他CSS样式... */
    </style>

</head>

<body>
    <table
        style="width:100%;max-width:1200px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tr style="padding:0px">
                            <td style="padding:2.5%;width: 60%;vertical-align:middle">
                                <h1 style="text-align: center;">Jinbin Bai</h1>

                                <p>
                                    I received B.S. in CS Degree from Nanjing University and high school diploma from
                                    the Affiliated High School of Shanxi University. After that, I studied at CS Dept.
                                    of National University of Singapore and founded <a
                                        href="https://huggingface.co/MeissonFlow">MeissonFlow Research</a> for
                                    developing masking paradigm.
                                </p>
                                <p>
                                    I am trying to find ways to build interactive models and algorithms for content
                                    creation. I want to build the world with visual prior, though i sadly agree that the
                                    language prior dominates current unified models. I love imagination, I love
                                    Astronomy. So I made an analogy in the figure below.
                                </p>




                                <!-- <p> -->
                                <!-- Email: jinbin5bai@gmail.com; jinbin.bai@u.nus.edu; jinbinb@acm.org -->
                                <!-- And I am always looking for Ph.D. opportunities. -->
                                <!-- </p> -->
                                <p style="text-align: center;">
                                    <a href="mailto:jinbin5bai@gmail.com">Email</a> &nbsp;/&nbsp;
                                    <!-- <a href="https://www.linkedin.com/in/jinbin-bai">Linkedin</a>&nbsp;/&nbsp; -->
                                    <a href="https://scholar.google.com/citations?hl=en&user=PAfNNrYAAAAJ">Google
                                        Scholar</a>&nbsp;/&nbsp;
                                    <a href="https://github.com/viiika">Github</a> &nbsp;/&nbsp;
                                    <a href="https://huggingface.co/BryanW">Hugging Face</a> &nbsp;/&nbsp;
                                    <!-- <a href="./VikaResearch.html">Vika Research</a> &nbsp;&nbsp;/&nbsp; -->
                                    <a href="https://x.com/Jinbin_Bai">X</a> &nbsp;
                                    <!-- /&nbsp; -->
                                    <!-- <a href="https://discord.gg/6B8XF58atz">Discord</a>  -->
                                    <!-- <a href="bio.txt">Short Bio</a> -->
                                </p>
                            </td>
                            <td style="padding:2.5%;width:25%;max-width:25%">
                                <img style="width:60%;max-width:100%" alt="profile photo"
                                    src="images/Jinbin_profile_new.jpg">
                                <p>
                                    Jinbin in Cambridge, UK, 2025.
                                </p>

                            </td>
                        </tr>
        </tbody>
    </table>


    <div style="text-align: center;">
        <img src="paper/gravity.jpeg" alt="Research"
            style="width: 100%; max-width: 80%; margin: 8px auto; display: block;">

        <p style="text-align: center; line-height: 1.6;">
            <a href="" style="display: block;">Universal gravity pulls matter into wells.</a>
            <a href="" style="display: block;">Gradient descent pulls models into minima.</a>
            <a href="" style="display: block;">Optimization landscapes are just the gravity wells of learning.</a>
            <a href="" style="display: block;">Some minima (like Mercury) are just... hard to reach.</a>
        </p>
    </div>



    <details close>
        <summary>
            <h2 style="display: inline;">News</h2>
        </summary>
        <ul>
            <li> <b>2025-09</b> &nbsp; Two papers accepted by <em>NeurIPS 2025</em>. </li>
        </ul>
        <ul>
            <li> <b>2025-06</b> &nbsp; Two papers accepted by <em>ICCV 2025</em>. </li>
        </ul>
        <ul>
            <li> <b>2025-04</b> &nbsp; One paper accepted by <em>CVPR 2025 AI for Content Creation Workshop</em>. </li>
        </ul>
        <ul>
            <li> <b>2025-04</b> &nbsp; One paper accepted by <em>IJCAI 2025</em>. </li>
        </ul>
        <ul>
            <li> <b>2025-04</b> &nbsp; Invited Talk from Riot Video Games. </li>
        </ul>
        <ul>
            <li> <b>2025-03</b> &nbsp; Awarded <em>Frontier Top Ten Young Scholars Award</em> (1st) from Century
                Frontier Asset Management. </li>
        </ul>
        <ul>
            <li> <b>2025-03</b> &nbsp; Invited Talk from University of Illinois Urbana-Champaign (UIUC). </li>
        </ul>
        <ul>
            <li> <b>2025-02</b> &nbsp; One paper accepted by <em>CVPR 2025</em>. </li>
        </ul>
        <ul>
            <li> <b>2025-01</b> &nbsp; One paper accepted by <em>ICLR 2025</em>, see you in Singapore! </li>
        </ul>
        <ul>
            <li><b>2024-12</b> &nbsp; One paper accepted by <em>AAAI 2025</em>. </li>
        </ul>
        <ul>
            <li> <b>2024-11</b> &nbsp; Invited Talk from Safe SuperIntelligence (SSI) Club. </li>
        </ul>
        <ul>
            <li> <b>2024-04</b> &nbsp; One paper accepted by <em>IJCAI 2024</em>, see you in Jeju! </li>
        </ul>
        <ul>
            <li> <b>2023-08</b> &nbsp; One paper accepted by <em>BMVC 2023</em>. </li>
        </ul>
        <ul>
            <li> <b>2023-07</b> &nbsp; Two papers accepted by <em>ACM MM 2023</em>. </li>
        </ul>
        <ul>
            <li> <b>2023-07</b> &nbsp; Two papers accepted by <em>ICCV 2023</em>. </li>
        </ul>
        <ul>
            <li> <b>2023-06</b> &nbsp; <em>Taming Diffusion Models for Music-driven Conducting Motion
                    Generation</em> accepted by <em>AAAI 2023 Summer Symposium</em>, with <b>Best Paper
                    Award</b>. </li>
        </ul>
        <ul>
            <li> <b>2023-05</b> &nbsp; One paper accepted by <em>ICIP 2023</em>, see you in Kuala Lumpur! </li>
        </ul>
        <ul>
            <li> <b>2023-02</b> &nbsp; <em>Translating natural language to planning goals with
                    large-language models</em> now on arxiv. </li>
        </ul>
        <ul>
            <li> <b>2022-11</b> &nbsp; One paper accepted by <em>ACCV 2022</em>. </li>
        </ul>
        <ul>
            <li> <b>2022-06</b> &nbsp; <em>LaT: Latent Translation with Cycle-Consistency for Video-Text
                    Retrieval</em> now on arxiv. </li>
        </ul>

        <ul>
            <li> <b>2021-03</b> &nbsp; Awarded as <em>Outstanding Graduate</em> by <em>Nanjing
                    University</em>. </li>
        </ul>
        <ul>
            <li> <b>2019-03</b> &nbsp; Awarded as <em>Outstanding Student</em> by <em>Nanjing
                    University</em>. </li>
        </ul>
    </details>

    <!-- <details close>
                        <summary>
                            <h2 style="display: inline;">Professional Services</h2>
                        </summary>

                        <ul>
                            <li> Reviewer:&nbsp; <em>ECCV 2022</em>, <em>ACCV 2022</em>, <em>CVPR 2023</em>, <em>ICCV
                                    2023</em>, <em>ACM MM 2023</em>, <em>EMNLP 2023</em>, <em>ICASSP 2024</em>, <em>CVPR
                                    2024</em>, <em>ICPR 2024</em>, <em>ECCV 2024</em>, <em>ACM MM 2024</em>, <em>COLM 2024</em>, <em>NeurIPS 2024</em>, <em>Artificial Intelligence Review</em>, <em>ICASSP 2025</em>, <em>ICLR 2025</em>, <em>AISTATS 2025</em>, <em>CVPR 2025</em>, <em>ICML 2025</em>, <em>IJCNN 2025</em>, <em>COLM 2025</em>, <em>ICCV 2025</em>, <em>NeurIPS 2025</em>, <em>AI for Content Creation workshop at CVPR 2025</em>    
                        </ul>
                        <ul>
                            <li> Program Committee Member:&nbsp; <em>AAAI 2023</em>, <em>AAAI 2024</em>, <em>AAAI 2025</em>
                        </ul>
                        <ul>
                            <li> ACM Professional Member</li>
                        </ul>
                    </details> -->

    <h2>Selected Publications</h2>

    <!-- <a href="pub.html">Full List</a> -->
    <table
                        style="width: 100%; margin-left:auto;margin-right:auto; border-width: 0px; border-spacing: 0px;">

                        <tbody>
                            <tr style="border-width: 1px">
                                <td style="border: 0px; padding: 20px">
                                    <img src="paper/guide.png" alt="guide"
                                       style=" width: 100px; margin-top: 8px">
                                </td>
                                <td style="border: 0px; padding: 20px">
                                    <div class="table-responsive">
                                        <table style="width: 100%;" class="table">
                                            <tbody>
                                                <tr>
                                                    <td style="width: 100%; text-align: left; border: 0px">
                                                        <p>
                                                            <br>
                                                            <b>From Masks to Worlds: A Hitchhiker’s Guide to World Models</b>
                                                            <br>
                                                            <strong>Jinbin Bai</strong>, Yu Lei, Hecong Wu, Yuchen Zhu, Shufan Li, Yi Xin, Xiangtai Li, Molei Tao, Aditya Grover, Ming-Hsuan Yang
                                                            <br>
                                                            Technical Report 2025
                                                            <br>
                                                            <a href="https://arxiv.org/abs/2510.20668">[Paper]</a>
                                                            <a
                                                            href="https://github.com/M-E-AGI-Lab/Awesome-World-Models">[GitHub]</a>

                                                            
                                                            <br>
                                                            A Hitchhiker’s guide for those who want to build worlds. We follow one clear road: from early masked models, to unified architectures that share a single paradigm, then to interactive generative models, and finally to memory-augmented systems that sustain consistent worlds over time. 
                                                            <br>
                                                        </p>
                                                    </td>
                                                    <td style="width: 10px;border: 0px">
                                                    </td>
                                                </tr>
                                            </tbody>
                                        </table>
                                    </div>
                                </td>
                            </tr>
                        </tbody>

                    </table>

    <table style="width: 100%; margin-left:auto;margin-right:auto; border-width: 0px; border-spacing: 0px;">

        <tbody>
            <tr style="border-width: 1px">
                <td style="border: 0px; padding: 20px">
                    <img src="paper/DiMOO.png" alt="DiMOO" style=" width: 100px; margin-top: 8px">
                </td>
                <td style="border: 0px; padding: 20px">
                    <div class="table-responsive">
                        <table style="width: 100%;" class="table">
                            <tbody>
                                <tr>
                                    <td style="width: 100%; text-align: left; border: 0px">
                                        <p>
                                            <br>
                                            <b>Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal
                                                Generation and Understanding</b>
                                            <br>
                                            Alpha VLLM Team
                                            <br>
                                            Technical Report 2025
                                            <br>
                                            <a href="https://arxiv.org/abs/2510.06308">[Paper]</a>
                                            <a href="https://huggingface.co/Alpha-VLLM/Lumina-DiMOO">[Model]</a>
                                            <a href="https://github.com/Alpha-VLLM/Lumina-DiMOO">[Code]</a>


                                            <br>
                                            Lumina-DiMOO is a unified discrete diffusion model that can not only
                                            generate high-resolution images, but support multimodal capabilities
                                            including text-to-image, image-to-image, and image understanding.
                                            <br>
                                        </p>
                                    </td>
                                    <td style="width: 10px;border: 0px">
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </td>
            </tr>
        </tbody>

    </table>

    <table style="width: 100%; margin-left:auto;margin-right:auto; border-width: 0px; border-spacing: 0px;">

        <tbody>
            <tr style="border-width: 1px">
                <td style="border: 0px; padding: 20px">
                    <img src="paper/Evolution.png" alt="Muddit" style=" width: 100px; margin-top: 8px">
                </td>
                <td style="border: 0px; padding: 20px">
                    <div class="table-responsive">
                        <table style="width: 100%;" class="table">
                            <tbody>
                                <tr>
                                    <td style="width: 100%; text-align: left; border: 0px">
                                        <p>
                                            <br>
                                            <b>Muddit: Liberating Generation Beyond Text-to-Image with a Unified Discrete Diffusion Model</b>
                                            <br>
                                            MeissonFlow Research
                                            <br>
                                            Technical Report 2025
                                            <br>
                                            <a href="https://arxiv.org/abs/2505.23606">[Paper]</a>
                                            <a href="https://huggingface.co/MeissonFlow/Muddit">[Model]</a>
                                            <a href="https://github.com/M-E-AGI-Lab/Muddit">[Code]</a>


                                            <br>
                                            Muddit (offical Meissonic II) is a unified discrete diffusion model that can not only
                                            generate high-resolution images, but support multimodal capabilities
                                            including text-to-image, image-to-text, and VQA. We verified one unified model can be trained from visual prior learned by Meissonic!
                                            <br>
                                        </p>
                                    </td>
                                    <td style="width: 10px;border: 0px">
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </td>
            </tr>
        </tbody>

    </table>


    <table style="width: 100%; margin-left:auto;margin-right:auto; border-width: 0px; border-spacing: 0px;">

        <tbody>
            <tr style="border-width: 1px">
                <td style="border: 0px; padding: 20px">
                    <img src="paper/Meissonic.png" alt="Meissonic" style="height: 100px; width: 100px; margin-top: 8px">
                </td>
                <td style="border: 0px; padding: 20px">
                    <div class="table-responsive">
                        <table style="width: 100%;" class="table">
                            <tbody>
                                <tr>
                                    <td style="width: 100%; text-align: left; border: 0px">
                                        <p>
                                            <br>
                                            <b>Meissonic: Revitalizing Masked Generative Transformers for Efficient
                                                High-Resolution Text-to-Image Synthesis</b>
                                            <br>
                                            MeissonFlow Research
                                            <br>
                                            ICLR 2025
                                            <br>
                                            <a href="https://arxiv.org/abs/2410.08261">[Paper]</a>
                                            <a href="https://huggingface.co/MeissonFlow/Meissonic">[Model]</a>
                                            <a href="https://github.com/viiika/Meissonic">[Code]</a>
                                            <a href="https://huggingface.co/spaces/MeissonFlow/meissonic">[Demo]</a>
                                            <a
                                                href="https://discord.com/channels/1305165461192966166/1305165622258303016">[Discord_Discussion]</a>
                                            <a href="https://www.youtube.com/watch?v=PlmifElhr6M">[Toturial_EN]</a>
                                            <a href="https://www.youtube.com/watch?v=rJDrf49wF64">[Toturial_JA]</a>
                                            <a
                                                href="https://mp.weixin.qq.com/s/0FULkgOeAyLnwR-u4AL1-A">[Media_Report_CN]</a>

                                            <br>
                                            Meissonic is a text-to-image discrete diffusion model that can generate
                                            high-resolution images. It is designed to run on consumer graphics cards.
                                            The left figure is generated by Meissonic.
                                            <br>
                                        </p>
                                    </td>
                                    <td style="width: 10px;border: 0px">
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </td>
            </tr>
        </tbody>

    </table>

    <details open>
        <summary>
            <h2 style="display: inline;">Miscellaneous</h2>
        </summary>
        <ul>
            <li>I am a huge fan of Cities: Skylines and I love designing and simulating cities. I can't
                wait for the release of Cities: Skylines II on Oct 24th, 2023! And, I've attended World Cities Summit
                (WCS) 2024 Conference!</li>
            <li>My favorite movies in recent years is Free Guy, and I dream of designing a game like
                this.</li>
            <li>In my leisure moments, I delight in playing the piano surrounded by abundant greenery, finding peace and
                emotional comfort in the solitude.</li>
            <li>I enjoy traveling and have visited 13 countries, guess where I have been?</li>
            <li>I like swimming, diving, surfing, beach under the sunshine.</li>
        </ul>
    </details>


    </td>
    </tr>
    <script id='clustrmaps'
        src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=Y9TH27aN8aIzbOU_6mOR3Oi70J95-HEqjFWoA2E0vYI&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script>



    </tbody>

    </table>
</body>

</html>